import torch
import torchaudio
import onnxruntime as ort
import numpy as np
import logging
import logging
import numpy as np
import onnxruntime as ort
import torchaudio
import torch
import os
from app.utils.model_utils import download_model

logger = logging.getLogger(__name__)

class AcousticAnalyzer:
    """
    Acoustic Sentiment Analyzer using a custom 1D-CNN model.
    
    Attributes:
        sample_rate (int): Expected sample rate (16000 Hz).
        n_mfcc (int): Number of MFCC features (40).
        time_steps (int): Fixed time steps for input (300 = 3 seconds).
    """
    def __init__(self):
        # MFCC Parameters (Must match train_acoustic_model.py)
        self.sample_rate = 16000
        self.n_mfcc = 40
        self.time_steps = 300 # 3 seconds
        
        # Use torchaudio for MFCC extraction
        self.mfcc_transform = torchaudio.transforms.MFCC(
            sample_rate=self.sample_rate,
            n_mfcc=self.n_mfcc,
            melkwargs={"n_fft": 400, "hop_length": 160, "n_mels": 64, "center": False}
        )
        
        # Load Custom ONNX Model
        # Path: models/custom/acoustic_cnn.onnx
        # If not found, we should probably error out or warn, but for now we assume it exists
        # as it was generated by the training script.
        model_path = os.path.join("models", "custom", "acoustic_cnn.onnx")
        
        if not os.path.exists(model_path):
            logger.warning(f"Custom model not found at {model_path}. Please run train_acoustic_model.py first.")
            # Fallback or Error? For now, let's error to be explicit
            raise FileNotFoundError(f"Custom model not found at {model_path}")

        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = 1
        sess_options.inter_op_num_threads = 1
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL
        
        try:
            self.session = ort.InferenceSession(model_path, sess_options)
            self.input_name = self.session.get_inputs()[0].name
            logger.info(f"Acoustic Model loaded: {model_path}")
        except Exception as e:
            logger.error(f"Failed to load ONNX model: {e}")
            raise

    def _preprocess(self, audio_bytes: bytes) -> np.ndarray:
        """
        Convert raw PCM bytes to MFCC tensor for the model.
        Input: Raw bytes (Int16)
        Output: (1, 40, 300) float32 numpy array
        """
        # 1. Convert bytes to float32 tensor
        audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
        waveform = torch.from_numpy(audio_int16).float() / 32768.0
        
        # Ensure shape is (1, samples)
        if waveform.dim() == 1:
            waveform = waveform.unsqueeze(0)
            
        # 2. Extract MFCC
        # Shape: (1, n_mfcc, time)
        mfcc = self.mfcc_transform(waveform)

        # 3. Instance Normalization (Must match training!)
        mean = mfcc.mean(dim=2, keepdim=True)
        std = mfcc.std(dim=2, keepdim=True)
        mfcc = (mfcc - mean) / (std + 1e-6)
        
        # 4. Pad or Crop to fixed time_steps (300)
        # Current shape: (1, 40, T)
        current_steps = mfcc.shape[2]
        target_steps = self.time_steps
        
        if current_steps < target_steps:
            pad_amount = target_steps - current_steps
            mfcc = torch.nn.functional.pad(mfcc, (0, pad_amount))
        else:
            mfcc = mfcc[:, :, :target_steps]
            
        # 5. Convert to numpy for ONNX Runtime
        return mfcc.numpy()

    def predict(self, audio_bytes: bytes):
        """
        Run inference on audio chunk.
        """
        try:
            input_tensor = self._preprocess(audio_bytes)
            
            # Run ONNX inference
            outputs = self.session.run(None, {self.input_name: input_tensor})
            logits = outputs[0][0] # (3,)
            
            # Softmax
            exp_logits = np.exp(logits - np.max(logits))
            probs = exp_logits / exp_logits.sum()
            
            class_id = int(np.argmax(probs))
            confidence = float(probs[class_id])
            
            # Map to Sentiment (Matches Notebook: 0=Negative, 1=Neutral, 2=Positive)
            labels = ["negative", "neutral", "positive"]
            sentiment = labels[class_id] if class_id < len(labels) else "unknown"
            
            return {
                "sentiment": sentiment,
                "confidence": round(confidence, 4),
                "raw_class_id": class_id,
                "scores": {
                    "neutral": float(probs[0]),
                    "positive": float(probs[1]),
                    "negative": float(probs[2])
                }
            }
            
        except Exception as e:
            logger.error(f"Inference error: {e}")
            return {"error": str(e)}
